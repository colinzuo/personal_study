{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = tf.constant([1.0, 2.0], name='a')\n",
    "b = tf.constant([2.0, 3.0], name='b')\n",
    "\n",
    "result = a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.,  5.], dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.4.5 完整神经网络样例程序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.81131822  1.48459876  0.06532937]\n",
      " [-2.44270396  0.0992484   0.59122431]]\n",
      "[[-0.81131822]\n",
      " [ 1.48459876]\n",
      " [ 0.06532937]]\n",
      "After 0 training step(s), cross entropy on all data is 0.0674925\n",
      "After 1000 training step(s), cross entropy on all data is 0.0163385\n",
      "After 2000 training step(s), cross entropy on all data is 0.00907547\n",
      "After 3000 training step(s), cross entropy on all data is 0.00714436\n",
      "After 4000 training step(s), cross entropy on all data is 0.00578471\n",
      "[[-1.9618274   2.58235407  1.68203783]\n",
      " [-3.4681716   1.06982327  2.11788988]]\n",
      "[[-1.8247149 ]\n",
      " [ 2.68546653]\n",
      " [ 1.41819501]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from numpy.random import RandomState\n",
    "\n",
    "batch_size = 8\n",
    "\n",
    "w1 = tf.Variable(tf.random_normal([2, 3], stddev=1, seed=1))\n",
    "w2 = tf.Variable(tf.random_normal([3, 1], stddev=1, seed=1))\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=(None, 2), name='x-input')\n",
    "y_ = tf.placeholder(tf.float32, shape=(None, 1), name='y-input')\n",
    "\n",
    "a = tf.matmul(x, w1)\n",
    "y = tf.matmul(a, w2)\n",
    "\n",
    "cross_entropy = -tf.reduce_mean(y_ * tf.log(tf.clip_by_value(y, 1e-10, 1.0)))\n",
    "train_step = tf.train.AdamOptimizer(0.001).minimize(cross_entropy)\n",
    "\n",
    "rdm = RandomState(1)\n",
    "dataset_size = 128\n",
    "X = rdm.rand(dataset_size, 2)\n",
    "Y = [[int(x1 + x2 < 1)] for (x1, x2) in X]\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init_op = tf.global_variables_initializer()\n",
    "    sess.run(init_op)\n",
    "    print(sess.run(w1))\n",
    "    print(sess.run(w2))\n",
    "    \n",
    "    STEPS = 5000\n",
    "    for i in range(STEPS):\n",
    "        start = (i * batch_size) % dataset_size\n",
    "        end = min(start + batch_size, dataset_size)\n",
    "        \n",
    "        sess.run(train_step, feed_dict={x: X[start:end], y_: Y[start:end]})\n",
    "        if i % 1000 == 0:\n",
    "            total_cross_entropy = sess.run(cross_entropy, feed_dict={x: X, y_: Y})\n",
    "            print(\"After %d training step(s), cross entropy on all data is %g\" %\n",
    "                 (i, total_cross_entropy))\n",
    "    \n",
    "    print(sess.run(w1))\n",
    "    print(sess.run(w2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.2.2 自定义损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After 0 training step(s), loss on all data is 814.831\n",
      "After 1000 training step(s), loss on all data is 187.065\n",
      "After 2000 training step(s), loss on all data is 93.1723\n",
      "After 3000 training step(s), loss on all data is 62.4251\n",
      "After 4000 training step(s), loss on all data is 28.8475\n",
      "[[ 1.07596886]\n",
      " [ 1.10207963]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from numpy.random import RandomState\n",
    "\n",
    "batch_size = 8\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=(None, 2), name='x-input')\n",
    "y_ = tf.placeholder(tf.float32, shape=(None, 1), name='y-input')\n",
    "\n",
    "w1 = tf.Variable(tf.random_normal([2, 1], stddev=1, seed=1))\n",
    "y = tf.matmul(x, w1)\n",
    "\n",
    "loss_less = 10\n",
    "loss_more = 1\n",
    "\n",
    "loss = tf.reduce_sum(tf.where(tf.greater(y, y_), (y - y_)*loss_more, (y_ - y)*loss_less))\n",
    "train_step = tf.train.AdamOptimizer(0.001).minimize(loss)\n",
    "\n",
    "rdm = RandomState(1)\n",
    "dataset_size = 128\n",
    "X = rdm.rand(dataset_size, 2)\n",
    "Y = [[x1 + x2 + rdm.rand()/10.0] for (x1, x2) in X]\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init_op = tf.global_variables_initializer()\n",
    "    sess.run(init_op)\n",
    "    \n",
    "    STEPS = 5000\n",
    "    for i in range(STEPS):\n",
    "        start = (i * batch_size) % dataset_size\n",
    "        end = min(start + batch_size, dataset_size)\n",
    "        \n",
    "        sess.run(train_step, feed_dict={x: X[start:end], y_: Y[start:end]})\n",
    "        if i % 1000 == 0:\n",
    "            total_loss = sess.run(loss, feed_dict={x: X, y_: Y})\n",
    "            print(\"After %d training step(s), loss on all data is %g\" %\n",
    "                 (i, total_loss))\n",
    "    \n",
    "    print(sess.run(w1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.1 MNIST 数据处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /Users/colinzuo/work/github/personal_study/tensorflow/book_caicloud/mnist/train-images-idx3-ubyte.gz\n",
      "Extracting /Users/colinzuo/work/github/personal_study/tensorflow/book_caicloud/mnist/train-labels-idx1-ubyte.gz\n",
      "Extracting /Users/colinzuo/work/github/personal_study/tensorflow/book_caicloud/mnist/t10k-images-idx3-ubyte.gz\n",
      "Extracting /Users/colinzuo/work/github/personal_study/tensorflow/book_caicloud/mnist/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import os\n",
    "\n",
    "if os.path.exists(\"/Users\"):\n",
    "    mnist = input_data.read_data_sets(\"/Users/colinzuo/work/github/personal_study/\"\n",
    "                                      \"tensorflow/book_caicloud/mnist/\", one_hot=True)\n",
    "else:\n",
    "    mnist = input_data.read_data_sets(\"D:\\\\work\\\\DataAnalysis\\\\study\\\\mnist\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data size:  55000\n",
      "Validating data size:  5000\n",
      "Testing data size:  10000\n",
      "Example training data:  [ 0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.38039219  0.37647063\n",
      "  0.3019608   0.46274513  0.2392157   0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.35294119  0.5411765\n",
      "  0.92156869  0.92156869  0.92156869  0.92156869  0.92156869  0.92156869\n",
      "  0.98431379  0.98431379  0.97254908  0.99607849  0.96078438  0.92156869\n",
      "  0.74509805  0.08235294  0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.54901963  0.98431379  0.99607849  0.99607849  0.99607849  0.99607849\n",
      "  0.99607849  0.99607849  0.99607849  0.99607849  0.99607849  0.99607849\n",
      "  0.99607849  0.99607849  0.99607849  0.99607849  0.74117649  0.09019608\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.88627458  0.99607849  0.81568635\n",
      "  0.78039223  0.78039223  0.78039223  0.78039223  0.54509807  0.2392157\n",
      "  0.2392157   0.2392157   0.2392157   0.2392157   0.50196081  0.8705883\n",
      "  0.99607849  0.99607849  0.74117649  0.08235294  0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.14901961  0.32156864  0.0509804   0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.13333334  0.83529419  0.99607849  0.99607849  0.45098042  0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.32941177  0.99607849  0.99607849  0.91764712  0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.32941177  0.99607849  0.99607849  0.91764712  0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.41568631  0.6156863   0.99607849  0.99607849  0.95294124  0.20000002\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.09803922  0.45882356  0.89411771\n",
      "  0.89411771  0.89411771  0.99215692  0.99607849  0.99607849  0.99607849\n",
      "  0.99607849  0.94117653  0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.26666668  0.4666667   0.86274517\n",
      "  0.99607849  0.99607849  0.99607849  0.99607849  0.99607849  0.99607849\n",
      "  0.99607849  0.99607849  0.99607849  0.55686277  0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.14509805  0.73333335  0.99215692\n",
      "  0.99607849  0.99607849  0.99607849  0.87450987  0.80784321  0.80784321\n",
      "  0.29411766  0.26666668  0.84313732  0.99607849  0.99607849  0.45882356\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.44313729\n",
      "  0.8588236   0.99607849  0.94901967  0.89019614  0.45098042  0.34901962\n",
      "  0.12156864  0.          0.          0.          0.          0.7843138\n",
      "  0.99607849  0.9450981   0.16078432  0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.66274512  0.99607849  0.6901961   0.24313727  0.          0.\n",
      "  0.          0.          0.          0.          0.          0.18823531\n",
      "  0.90588242  0.99607849  0.91764712  0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.07058824  0.48627454  0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.32941177  0.99607849  0.99607849  0.65098041  0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.54509807  0.99607849  0.9333334   0.22352943  0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.82352948  0.98039222  0.99607849  0.65882355  0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.94901967  0.99607849  0.93725497  0.22352943  0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.34901962  0.98431379  0.9450981   0.33725491  0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.01960784  0.80784321  0.96470594  0.6156863   0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.01568628  0.45882356  0.27058825  0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.        ]\n",
      "Example training label:  [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "print(\"Training data size: \", mnist.train.num_examples)\n",
    "print(\"Validating data size: \", mnist.validation.num_examples)\n",
    "print(\"Testing data size: \", mnist.test.num_examples)\n",
    "print(\"Example training data: \", mnist.train.images[0])\n",
    "print(\"Example training label: \", mnist.train.labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape:  (100, 784)\n",
      "Y shape:  (100, 10)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "xs, ys = mnist.train.next_batch(batch_size)\n",
    "print(\"X shape: \", xs.shape)\n",
    "print(\"Y shape: \", ys.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.2.1 TensorFlow 训练神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /Users/colinzuo/work/github/personal_study/tensorflow/book_caicloud/mnist/train-images-idx3-ubyte.gz\n",
      "Extracting /Users/colinzuo/work/github/personal_study/tensorflow/book_caicloud/mnist/train-labels-idx1-ubyte.gz\n",
      "Extracting /Users/colinzuo/work/github/personal_study/tensorflow/book_caicloud/mnist/t10k-images-idx3-ubyte.gz\n",
      "Extracting /Users/colinzuo/work/github/personal_study/tensorflow/book_caicloud/mnist/t10k-labels-idx1-ubyte.gz\n",
      "After 0 training step(s), validation accuracy using average model is 0.1008, test accuracy using average model is 0.1115\n",
      "After 1000 training step(s), validation accuracy using average model is 0.9786, test accuracy using average model is 0.9743\n",
      "After 2000 training step(s), validation accuracy using average model is 0.9832, test accuracy using average model is 0.9799\n",
      "After 3000 training step(s), validation accuracy using average model is 0.9812, test accuracy using average model is 0.9819\n",
      "After 4000 training step(s), validation accuracy using average model is 0.983, test accuracy using average model is 0.9815\n",
      "After 5000 training step(s), validation accuracy using average model is 0.9836, test accuracy using average model is 0.9821\n",
      "After 6000 training step(s), validation accuracy using average model is 0.9832, test accuracy using average model is 0.9826\n",
      "After 7000 training step(s), validation accuracy using average model is 0.9844, test accuracy using average model is 0.983\n",
      "After 8000 training step(s), validation accuracy using average model is 0.9846, test accuracy using average model is 0.9823\n",
      "After 9000 training step(s), validation accuracy using average model is 0.9838, test accuracy using average model is 0.9831\n",
      "After 10000 training step(s), validation accuracy using average model is 0.9844, test accuracy using average model is 0.9828\n",
      "After 11000 training step(s), validation accuracy using average model is 0.9848, test accuracy using average model is 0.983\n",
      "After 12000 training step(s), validation accuracy using average model is 0.9846, test accuracy using average model is 0.9836\n",
      "After 13000 training step(s), validation accuracy using average model is 0.9852, test accuracy using average model is 0.9838\n",
      "After 14000 training step(s), validation accuracy using average model is 0.9844, test accuracy using average model is 0.9834\n",
      "After 15000 training step(s), validation accuracy using average model is 0.9842, test accuracy using average model is 0.9838\n",
      "After 16000 training step(s), validation accuracy using average model is 0.9844, test accuracy using average model is 0.9839\n",
      "After 17000 training step(s), validation accuracy using average model is 0.985, test accuracy using average model is 0.9836\n",
      "After 18000 training step(s), validation accuracy using average model is 0.9852, test accuracy using average model is 0.9839\n",
      "After 19000 training step(s), validation accuracy using average model is 0.985, test accuracy using average model is 0.9834\n",
      "After 20000 training step(s), validation accuracy using average model is 0.9856, test accuracy using average model is 0.9836\n",
      "After 21000 training step(s), validation accuracy using average model is 0.9844, test accuracy using average model is 0.9839\n",
      "After 22000 training step(s), validation accuracy using average model is 0.9844, test accuracy using average model is 0.9842\n",
      "After 23000 training step(s), validation accuracy using average model is 0.9846, test accuracy using average model is 0.9839\n",
      "After 24000 training step(s), validation accuracy using average model is 0.9854, test accuracy using average model is 0.9838\n",
      "After 25000 training step(s), validation accuracy using average model is 0.985, test accuracy using average model is 0.9843\n",
      "After 26000 training step(s), validation accuracy using average model is 0.9848, test accuracy using average model is 0.9834\n",
      "After 27000 training step(s), validation accuracy using average model is 0.985, test accuracy using average model is 0.983\n",
      "After 28000 training step(s), validation accuracy using average model is 0.9848, test accuracy using average model is 0.9839\n",
      "After 29000 training step(s), validation accuracy using average model is 0.9854, test accuracy using average model is 0.9832\n",
      "After 30000 training steps, test accuracy using average model is 0.9841\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "INPUT_NODE = 784\n",
    "OUTPUT_NODE = 10\n",
    "\n",
    "LAYER1_NODE = 500\n",
    "BATCH_SIZE = 100\n",
    "\n",
    "LEARNING_RATE_BASE = 0.8\n",
    "LEARNING_RATE_DECAY = 0.99\n",
    "\n",
    "REGULARIZATION_RATE = 0.0001\n",
    "TRAINING_STEPS = 30000\n",
    "MOVING_AVERAGES_DECAY = 0.99\n",
    "\n",
    "def inference(input_tensor, avg_class, weights1, biases1, weights2, biases2):\n",
    "    if avg_class == None:\n",
    "        layer1 = tf.nn.relu(tf.matmul(input_tensor, weights1) + biases1)\n",
    "        \n",
    "        return tf.matmul(layer1, weights2) + biases2\n",
    "    else:\n",
    "        layer1 = tf.nn.relu(tf.matmul(input_tensor, avg_class.average(weights1)) + avg_class.average(biases1))\n",
    "        \n",
    "        return tf.matmul(layer1, avg_class.average(weights2)) + avg_class.average(biases2)\n",
    "    \n",
    "def train(mnist):\n",
    "    x = tf.placeholder(tf.float32, [None, INPUT_NODE], name='x-input')\n",
    "    y_ = tf.placeholder(tf.float32, [None, OUTPUT_NODE], name='y-input')\n",
    "    \n",
    "    weights1 = tf.Variable(tf.truncated_normal([INPUT_NODE, LAYER1_NODE], stddev=0.1))\n",
    "    biases1 = tf.Variable(tf.constant(0.1, shape=[LAYER1_NODE]))\n",
    "    \n",
    "    weights2 = tf.Variable(tf.truncated_normal([LAYER1_NODE, OUTPUT_NODE], stddev=0.1))\n",
    "    biases2 = tf.Variable(tf.constant(0.1, shape=[OUTPUT_NODE]))\n",
    "    \n",
    "    y = inference(x, None, weights1, biases1, weights2, biases2)\n",
    "    \n",
    "    global_step = tf.Variable(0, trainable=False)\n",
    "    \n",
    "    variable_averages = tf.train.ExponentialMovingAverage(MOVING_AVERAGES_DECAY, global_step)\n",
    "    \n",
    "    variables_average_op = variable_averages.apply(tf.trainable_variables())\n",
    "    \n",
    "    average_y = inference(x, variable_averages, weights1, biases1, weights2, biases2)\n",
    "    \n",
    "    cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=y, labels=tf.argmax(y_, 1))\n",
    "    cross_entropy_mean = tf.reduce_mean(cross_entropy)\n",
    "    \n",
    "    regularizer = tf.contrib.layers.l2_regularizer(REGULARIZATION_RATE)\n",
    "    regularization = regularizer(weights1) + regularizer(weights2)\n",
    "    loss = cross_entropy_mean + regularization\n",
    "    \n",
    "    learning_rate = tf.train.exponential_decay(LEARNING_RATE_BASE, global_step, \n",
    "                                               mnist.train.num_examples / BATCH_SIZE, LEARNING_RATE_DECAY)\n",
    "    train_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss, global_step=global_step)\n",
    "    \n",
    "    with tf.control_dependencies([train_step, variables_average_op]):\n",
    "        train_op = tf.no_op(name='train')\n",
    "        \n",
    "    correct_prediction = tf.equal(tf.argmax(average_y, 1), tf.argmax(y_, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        tf.global_variables_initializer().run()\n",
    "        validate_feed = {x: mnist.validation.images, y_: mnist.validation.labels}\n",
    "        test_feed = {x: mnist.test.images, y_: mnist.test.labels}\n",
    "        \n",
    "        for i in range(TRAINING_STEPS):\n",
    "            if i % 1000 == 0:\n",
    "                validate_acc = sess.run(accuracy, feed_dict=validate_feed)\n",
    "                test_acc = sess.run(accuracy, feed_dict=test_feed)\n",
    "                print(\"After %d training step(s), validation accuracy using average model is %g, \"\n",
    "                      \"test accuracy using average model is %g\" % (i, validate_acc, test_acc))\n",
    "            \n",
    "            xs, ys = mnist.train.next_batch(BATCH_SIZE)\n",
    "            sess.run(train_op, feed_dict={x: xs, y_: ys})\n",
    "        \n",
    "        test_acc = sess.run(accuracy, feed_dict=test_feed)\n",
    "        print(\"After %d training steps, test accuracy using average model is %g\" % (TRAINING_STEPS, test_acc))\n",
    "        \n",
    "def main(argv=None):\n",
    "    import os\n",
    "\n",
    "    if os.path.exists(\"/Users\"):\n",
    "        mnist = input_data.read_data_sets(\"/Users/colinzuo/work/github/personal_study/\"\n",
    "                                          \"tensorflow/book_caicloud/mnist/\", one_hot=True)\n",
    "    else:\n",
    "        mnist = input_data.read_data_sets(\"D:\\\\work\\\\DataAnalysis\\\\study\\\\mnist\", one_hot=True)\n",
    "        \n",
    "    train(mnist)\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 5.4.1 持久化代码实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "v1 = tf.Variable(tf.constant(1.0, shape=[1]), name=\"v1\")\n",
    "v2 = tf.Variable(tf.constant(2.0, shape=[1]), name=\"v2\")\n",
    "result = v1 + v2\n",
    "\n",
    "init_op = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "model_path = os.path.join(\"model\", \"model.ckpt\")\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init_op)\n",
    "    saver.save(sess, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "v1 = tf.Variable(tf.constant(1.0, shape=[1]), name='v1')\n",
    "v2 = tf.Variable(tf.constant(2.0, shape=[1]), name='v2')\n",
    "result = v1 + v2\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "model_path = os.path.join(\"model\", \"model.ckpt\")\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, model_path)\n",
    "    print(sess.run(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "model_path = os.path.join(\"model\", \"model.ckpt\")\n",
    "meta_path = model_path + \".meta\"\n",
    "saver = tf.train.import_meta_graph(meta_path)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, model_path)\n",
    "    print(sess.run(tf.get_default_graph().get_tensor_by_name(\"add:0\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "v1 = tf.Variable(tf.constant(1.0, shape=[1]), name='other-v1')\n",
    "v2 = tf.Variable(tf.constant(2.0, shape=[1]), name='other-v2')\n",
    "result = v1 + v2\n",
    "\n",
    "saver = tf.train.Saver({\"v1\": v1, \"v2\": v2})\n",
    "model_path = os.path.join(\"model\", \"model.ckpt\")\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, model_path)\n",
    "    print(sess.run(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable:0\n",
      "Variable_1:0\n",
      "beta1_power:0\n",
      "beta2_power:0\n",
      "Variable/Adam:0\n",
      "Variable/Adam_1:0\n",
      "Variable_1/Adam:0\n",
      "Variable_1/Adam_1:0\n",
      "Variable_2:0\n",
      "beta1_power_1:0\n",
      "beta2_power_1:0\n",
      "Variable_2/Adam:0\n",
      "Variable_2/Adam_1:0\n",
      "Variable_3:0\n",
      "Variable_4:0\n",
      "Variable_5:0\n",
      "Variable_6:0\n",
      "Variable_7:0\n",
      "Variable_8:0\n",
      "Variable_9:0\n",
      "Variable/ExponentialMovingAverage:0\n",
      "Variable_1/ExponentialMovingAverage:0\n",
      "Variable_2/ExponentialMovingAverage:0\n",
      "Variable_3/ExponentialMovingAverage:0\n",
      "Variable_4/ExponentialMovingAverage:0\n",
      "Variable_5/ExponentialMovingAverage:0\n",
      "Variable_6/ExponentialMovingAverage:0\n",
      "Variable_7/ExponentialMovingAverage:0\n",
      "Variable_8/ExponentialMovingAverage:0\n",
      "Variable_10:0\n",
      "Variable_11:0\n",
      "Variable_12:0\n",
      "Variable_13:0\n",
      "Variable_14:0\n",
      "Variable/ExponentialMovingAverage_1:0\n",
      "Variable_1/ExponentialMovingAverage_1:0\n",
      "Variable_2/ExponentialMovingAverage_1:0\n",
      "Variable_3/ExponentialMovingAverage_1:0\n",
      "Variable_4/ExponentialMovingAverage_1:0\n",
      "Variable_5/ExponentialMovingAverage_1:0\n",
      "Variable_6/ExponentialMovingAverage_1:0\n",
      "Variable_7/ExponentialMovingAverage_1:0\n",
      "Variable_8/ExponentialMovingAverage_1:0\n",
      "Variable_10/ExponentialMovingAverage:0\n",
      "Variable_11/ExponentialMovingAverage:0\n",
      "Variable_12/ExponentialMovingAverage:0\n",
      "Variable_13/ExponentialMovingAverage:0\n",
      "v1:0\n",
      "v2:0\n",
      "v1_1:0\n",
      "v2_1:0\n",
      "v1_2:0\n",
      "v2_2:0\n",
      "v1_3:0\n",
      "v2_3:0\n",
      "v1_4:0\n",
      "v2_4:0\n",
      "v1_5:0\n",
      "v2_5:0\n",
      "v1_6:0\n",
      "v2_6:0\n",
      "v1_7:0\n",
      "v2_7:0\n",
      "v:0\n",
      "Variable/ExponentialMovingAverage_2:0\n",
      "Variable_1/ExponentialMovingAverage_2:0\n",
      "beta1_power/ExponentialMovingAverage:0\n",
      "beta2_power/ExponentialMovingAverage:0\n",
      "Variable/Adam/ExponentialMovingAverage:0\n",
      "Variable/Adam_1/ExponentialMovingAverage:0\n",
      "Variable_1/Adam/ExponentialMovingAverage:0\n",
      "Variable_1/Adam_1/ExponentialMovingAverage:0\n",
      "Variable_2/ExponentialMovingAverage_2:0\n",
      "beta1_power_1/ExponentialMovingAverage:0\n",
      "beta2_power_1/ExponentialMovingAverage:0\n",
      "Variable_2/Adam/ExponentialMovingAverage:0\n",
      "Variable_2/Adam_1/ExponentialMovingAverage:0\n",
      "Variable_3/ExponentialMovingAverage_2:0\n",
      "Variable_4/ExponentialMovingAverage_2:0\n",
      "Variable_5/ExponentialMovingAverage_2:0\n",
      "Variable_6/ExponentialMovingAverage_2:0\n",
      "Variable_7/ExponentialMovingAverage_2:0\n",
      "Variable_8/ExponentialMovingAverage_2:0\n",
      "v_1:0\n",
      "Variable/ExponentialMovingAverage_3:0\n",
      "Variable_1/ExponentialMovingAverage_3:0\n",
      "beta1_power/ExponentialMovingAverage_1:0\n",
      "beta2_power/ExponentialMovingAverage_1:0\n",
      "Variable/Adam/ExponentialMovingAverage_1:0\n",
      "Variable/Adam_1/ExponentialMovingAverage_1:0\n",
      "Variable_1/Adam/ExponentialMovingAverage_1:0\n",
      "Variable_1/Adam_1/ExponentialMovingAverage_1:0\n",
      "Variable_2/ExponentialMovingAverage_3:0\n",
      "beta1_power_1/ExponentialMovingAverage_1:0\n",
      "beta2_power_1/ExponentialMovingAverage_1:0\n",
      "Variable_2/Adam/ExponentialMovingAverage_1:0\n",
      "Variable_2/Adam_1/ExponentialMovingAverage_1:0\n",
      "Variable_3/ExponentialMovingAverage_3:0\n",
      "Variable_4/ExponentialMovingAverage_3:0\n",
      "Variable_5/ExponentialMovingAverage_3:0\n",
      "Variable_6/ExponentialMovingAverage_3:0\n",
      "Variable_7/ExponentialMovingAverage_3:0\n",
      "Variable_8/ExponentialMovingAverage_3:0\n",
      "v_2:0\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "The variables must be half, float, or double: Variable_9:0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-c982f5efb71b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mema\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExponentialMovingAverage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.99\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mmaintain_averages_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mema\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"After ema\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/colinzuo/anaconda/envs/python35/lib/python3.5/site-packages/tensorflow/python/training/moving_averages.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, var_list)\u001b[0m\n\u001b[1;32m    353\u001b[0m                                       dtypes.float64]:\n\u001b[1;32m    354\u001b[0m         raise TypeError(\"The variables must be half, float, or double: %s\" %\n\u001b[0;32m--> 355\u001b[0;31m                         var.name)\n\u001b[0m\u001b[1;32m    356\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mvar\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_averages\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Moving average already computed for: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: The variables must be half, float, or double: Variable_9:0"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "v = tf.Variable(0, dtype=tf.float32, name=\"v\")\n",
    "\n",
    "for variable in tf.global_variables():\n",
    "    print(variable.name)\n",
    "    \n",
    "ema = tf.train.ExponentialMovingAverage(0.99)\n",
    "maintain_averages_op = ema.apply(tf.global_variables())\n",
    "\n",
    "print(\"After ema\")\n",
    "\n",
    "for variable in tf.global_variables():\n",
    "    print(variable.name)\n",
    "    \n",
    "saver = tf.train.Saver()\n",
    "model_path = os.path.join(\"model\", \"model_2.ckpt\")\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init_op = tf.global_variables_initializer()\n",
    "    sess.run(init_op)\n",
    "    \n",
    "    sess.run(tf.assign(v, 10))\n",
    "    sess.run(maintain_averages_op)\n",
    "    saver.save(sess, model_path)\n",
    "    print(sess.run([v, ema.average(v)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from model/model_2.ckpt\n",
      "0.0999999\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "v = tf.Variable(0, dtype=tf.float32, name=\"v\")\n",
    "    \n",
    "saver = tf.train.Saver({\"v/ExponentialMovingAverage\": v})\n",
    "model_path = os.path.join(\"model\", \"model_2.ckpt\")\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, model_path)\n",
    "    print(sess.run(v))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Variable/ExponentialMovingAverage': <tf.Variable 'Variable/ExponentialMovingAverage:0' shape=(2, 3) dtype=float32_ref>, 'Variable_1/Adam_1/ExponentialMovingAverage': <tf.Variable 'Variable_1/Adam_1/ExponentialMovingAverage:0' shape=(3, 1) dtype=float32_ref>, 'Variable_5/ExponentialMovingAverage_2': <tf.Variable 'Variable_5/ExponentialMovingAverage_2:0' shape=(784, 500) dtype=float32_ref>, 'v_4/ExponentialMovingAverage': <tf.Variable 'v_4:0' shape=() dtype=float32_ref>, 'v/ExponentialMovingAverage': <tf.Variable 'v:0' shape=() dtype=float32_ref>, 'v_2/ExponentialMovingAverage': <tf.Variable 'v_2:0' shape=() dtype=float32_ref>, 'v2_5/ExponentialMovingAverage': <tf.Variable 'v2_5:0' shape=(1,) dtype=float32_ref>, 'Variable_1/Adam_1/ExponentialMovingAverage_3': <tf.Variable 'Variable_1/Adam_1:0' shape=(3, 1) dtype=float32_ref>, 'Variable_4/ExponentialMovingAverage_1': <tf.Variable 'Variable_4/ExponentialMovingAverage_1:0' shape=(500,) dtype=float32_ref>, 'beta1_power_1/ExponentialMovingAverage_3': <tf.Variable 'beta1_power_1:0' shape=() dtype=float32_ref>, 'Variable_3/ExponentialMovingAverage_5': <tf.Variable 'Variable_3:0' shape=(784, 500) dtype=float32_ref>, 'Variable_2/Adam_1/ExponentialMovingAverage_2': <tf.Variable 'Variable_2/Adam_1/ExponentialMovingAverage_2:0' shape=(2, 1) dtype=float32_ref>, 'Variable_2/ExponentialMovingAverage_1': <tf.Variable 'Variable_2/ExponentialMovingAverage_1:0' shape=(2, 1) dtype=float32_ref>, 'Variable_4/ExponentialMovingAverage': <tf.Variable 'Variable_4/ExponentialMovingAverage:0' shape=(500,) dtype=float32_ref>, 'Variable_8/ExponentialMovingAverage_4': <tf.Variable 'Variable_8/ExponentialMovingAverage_4:0' shape=(10,) dtype=float32_ref>, 'v1_2/ExponentialMovingAverage': <tf.Variable 'v1_2:0' shape=(1,) dtype=float32_ref>, 'Variable_4/ExponentialMovingAverage_3': <tf.Variable 'Variable_4/ExponentialMovingAverage_3:0' shape=(500,) dtype=float32_ref>, 'Variable_12/ExponentialMovingAverage_1': <tf.Variable 'Variable_12:0' shape=(500, 10) dtype=float32_ref>, 'Variable_1/Adam/ExponentialMovingAverage': <tf.Variable 'Variable_1/Adam/ExponentialMovingAverage:0' shape=(3, 1) dtype=float32_ref>, 'Variable_8/ExponentialMovingAverage_2': <tf.Variable 'Variable_8/ExponentialMovingAverage_2:0' shape=(10,) dtype=float32_ref>, 'Variable_3/ExponentialMovingAverage_2': <tf.Variable 'Variable_3/ExponentialMovingAverage_2:0' shape=(784, 500) dtype=float32_ref>, 'v2_4/ExponentialMovingAverage': <tf.Variable 'v2_4:0' shape=(1,) dtype=float32_ref>, 'v_1/ExponentialMovingAverage': <tf.Variable 'v_1:0' shape=() dtype=float32_ref>, 'Variable_10/ExponentialMovingAverage': <tf.Variable 'Variable_10/ExponentialMovingAverage:0' shape=(784, 500) dtype=float32_ref>, 'Variable_1/ExponentialMovingAverage_2': <tf.Variable 'Variable_1/ExponentialMovingAverage_2:0' shape=(3, 1) dtype=float32_ref>, 'v1_7/ExponentialMovingAverage': <tf.Variable 'v1_7:0' shape=(1,) dtype=float32_ref>, 'beta2_power_1/ExponentialMovingAverage_2': <tf.Variable 'beta2_power_1/ExponentialMovingAverage_2:0' shape=() dtype=float32_ref>, 'Variable_13/ExponentialMovingAverage_1': <tf.Variable 'Variable_13:0' shape=(10,) dtype=float32_ref>, 'v2/ExponentialMovingAverage': <tf.Variable 'v2:0' shape=(1,) dtype=float32_ref>, 'Variable_4/ExponentialMovingAverage_2': <tf.Variable 'Variable_4/ExponentialMovingAverage_2:0' shape=(500,) dtype=float32_ref>, 'Variable_1/Adam/ExponentialMovingAverage_1': <tf.Variable 'Variable_1/Adam/ExponentialMovingAverage_1:0' shape=(3, 1) dtype=float32_ref>, 'Variable_7/ExponentialMovingAverage_1': <tf.Variable 'Variable_7/ExponentialMovingAverage_1:0' shape=(500, 10) dtype=float32_ref>, 'Variable_3/ExponentialMovingAverage_3': <tf.Variable 'Variable_3/ExponentialMovingAverage_3:0' shape=(784, 500) dtype=float32_ref>, 'Variable_8/ExponentialMovingAverage_3': <tf.Variable 'Variable_8/ExponentialMovingAverage_3:0' shape=(10,) dtype=float32_ref>, 'v2_1/ExponentialMovingAverage': <tf.Variable 'v2_1:0' shape=(1,) dtype=float32_ref>, 'Variable/ExponentialMovingAverage_3': <tf.Variable 'Variable/ExponentialMovingAverage_3:0' shape=(2, 3) dtype=float32_ref>, 'Variable_13/ExponentialMovingAverage': <tf.Variable 'Variable_13/ExponentialMovingAverage:0' shape=(10,) dtype=float32_ref>, 'Variable_2/Adam_1/ExponentialMovingAverage': <tf.Variable 'Variable_2/Adam_1/ExponentialMovingAverage:0' shape=(2, 1) dtype=float32_ref>, 'Variable_5/ExponentialMovingAverage_5': <tf.Variable 'Variable_5:0' shape=(784, 500) dtype=float32_ref>, 'Variable_6/ExponentialMovingAverage_2': <tf.Variable 'Variable_6/ExponentialMovingAverage_2:0' shape=(500,) dtype=float32_ref>, 'Variable_12/ExponentialMovingAverage': <tf.Variable 'Variable_12/ExponentialMovingAverage:0' shape=(500, 10) dtype=float32_ref>, 'Variable_5/ExponentialMovingAverage_3': <tf.Variable 'Variable_5/ExponentialMovingAverage_3:0' shape=(784, 500) dtype=float32_ref>, 'v1/ExponentialMovingAverage': <tf.Variable 'v1:0' shape=(1,) dtype=float32_ref>, 'Variable_10/ExponentialMovingAverage_1': <tf.Variable 'Variable_10:0' shape=(784, 500) dtype=float32_ref>, 'Variable_6/ExponentialMovingAverage_1': <tf.Variable 'Variable_6/ExponentialMovingAverage_1:0' shape=(500,) dtype=float32_ref>, 'Variable_1/Adam/ExponentialMovingAverage_2': <tf.Variable 'Variable_1/Adam/ExponentialMovingAverage_2:0' shape=(3, 1) dtype=float32_ref>, 'Variable/Adam/ExponentialMovingAverage_3': <tf.Variable 'Variable/Adam:0' shape=(2, 3) dtype=float32_ref>, 'v1_6/ExponentialMovingAverage': <tf.Variable 'v1_6:0' shape=(1,) dtype=float32_ref>, 'Variable/Adam_1/ExponentialMovingAverage_2': <tf.Variable 'Variable/Adam_1/ExponentialMovingAverage_2:0' shape=(2, 3) dtype=float32_ref>, 'Variable_9': <tf.Variable 'Variable_9:0' shape=() dtype=int32_ref>, 'beta2_power_1/ExponentialMovingAverage_1': <tf.Variable 'beta2_power_1/ExponentialMovingAverage_1:0' shape=() dtype=float32_ref>, 'Variable_7/ExponentialMovingAverage_4': <tf.Variable 'Variable_7/ExponentialMovingAverage_4:0' shape=(500, 10) dtype=float32_ref>, 'v1_3/ExponentialMovingAverage': <tf.Variable 'v1_3:0' shape=(1,) dtype=float32_ref>, 'beta1_power/ExponentialMovingAverage': <tf.Variable 'beta1_power/ExponentialMovingAverage:0' shape=() dtype=float32_ref>, 'Variable_2/Adam/ExponentialMovingAverage_3': <tf.Variable 'Variable_2/Adam:0' shape=(2, 1) dtype=float32_ref>, 'Variable/Adam/ExponentialMovingAverage_2': <tf.Variable 'Variable/Adam/ExponentialMovingAverage_2:0' shape=(2, 3) dtype=float32_ref>, 'v2_6/ExponentialMovingAverage': <tf.Variable 'v2_6:0' shape=(1,) dtype=float32_ref>, 'Variable_3/ExponentialMovingAverage_4': <tf.Variable 'Variable_3/ExponentialMovingAverage_4:0' shape=(784, 500) dtype=float32_ref>, 'beta1_power/ExponentialMovingAverage_1': <tf.Variable 'beta1_power/ExponentialMovingAverage_1:0' shape=() dtype=float32_ref>, 'beta2_power/ExponentialMovingAverage': <tf.Variable 'beta2_power/ExponentialMovingAverage:0' shape=() dtype=float32_ref>, 'Variable_5/ExponentialMovingAverage': <tf.Variable 'Variable_5/ExponentialMovingAverage:0' shape=(784, 500) dtype=float32_ref>, 'Variable/Adam_1/ExponentialMovingAverage': <tf.Variable 'Variable/Adam_1/ExponentialMovingAverage:0' shape=(2, 3) dtype=float32_ref>, 'Variable_7/ExponentialMovingAverage_2': <tf.Variable 'Variable_7/ExponentialMovingAverage_2:0' shape=(500, 10) dtype=float32_ref>, 'v1_5/ExponentialMovingAverage': <tf.Variable 'v1_5:0' shape=(1,) dtype=float32_ref>, 'Variable_11/ExponentialMovingAverage_1': <tf.Variable 'Variable_11:0' shape=(500,) dtype=float32_ref>, 'Variable_8/ExponentialMovingAverage_5': <tf.Variable 'Variable_8:0' shape=(10,) dtype=float32_ref>, 'Variable_2/ExponentialMovingAverage_2': <tf.Variable 'Variable_2/ExponentialMovingAverage_2:0' shape=(2, 1) dtype=float32_ref>, 'Variable/ExponentialMovingAverage_5': <tf.Variable 'Variable:0' shape=(2, 3) dtype=float32_ref>, 'Variable_6/ExponentialMovingAverage_4': <tf.Variable 'Variable_6/ExponentialMovingAverage_4:0' shape=(500,) dtype=float32_ref>, 'Variable/ExponentialMovingAverage_1': <tf.Variable 'Variable/ExponentialMovingAverage_1:0' shape=(2, 3) dtype=float32_ref>, 'Variable_2/Adam/ExponentialMovingAverage_1': <tf.Variable 'Variable_2/Adam/ExponentialMovingAverage_1:0' shape=(2, 1) dtype=float32_ref>, 'v2_2/ExponentialMovingAverage': <tf.Variable 'v2_2:0' shape=(1,) dtype=float32_ref>, 'v2_3/ExponentialMovingAverage': <tf.Variable 'v2_3:0' shape=(1,) dtype=float32_ref>, 'Variable_2/ExponentialMovingAverage_3': <tf.Variable 'Variable_2/ExponentialMovingAverage_3:0' shape=(2, 1) dtype=float32_ref>, 'v2_7/ExponentialMovingAverage': <tf.Variable 'v2_7:0' shape=(1,) dtype=float32_ref>, 'Variable/Adam_1/ExponentialMovingAverage_1': <tf.Variable 'Variable/Adam_1/ExponentialMovingAverage_1:0' shape=(2, 3) dtype=float32_ref>, 'v1_4/ExponentialMovingAverage': <tf.Variable 'v1_4:0' shape=(1,) dtype=float32_ref>, 'Variable_2/ExponentialMovingAverage_4': <tf.Variable 'Variable_2/ExponentialMovingAverage_4:0' shape=(2, 1) dtype=float32_ref>, 'Variable_2/Adam_1/ExponentialMovingAverage_1': <tf.Variable 'Variable_2/Adam_1/ExponentialMovingAverage_1:0' shape=(2, 1) dtype=float32_ref>, 'Variable_8/ExponentialMovingAverage_1': <tf.Variable 'Variable_8/ExponentialMovingAverage_1:0' shape=(10,) dtype=float32_ref>, 'Variable_3/ExponentialMovingAverage_1': <tf.Variable 'Variable_3/ExponentialMovingAverage_1:0' shape=(784, 500) dtype=float32_ref>, 'Variable/Adam_1/ExponentialMovingAverage_3': <tf.Variable 'Variable/Adam_1:0' shape=(2, 3) dtype=float32_ref>, 'beta1_power/ExponentialMovingAverage_2': <tf.Variable 'beta1_power/ExponentialMovingAverage_2:0' shape=() dtype=float32_ref>, 'beta2_power_1/ExponentialMovingAverage': <tf.Variable 'beta2_power_1/ExponentialMovingAverage:0' shape=() dtype=float32_ref>, 'beta1_power_1/ExponentialMovingAverage': <tf.Variable 'beta1_power_1/ExponentialMovingAverage:0' shape=() dtype=float32_ref>, 'Variable/ExponentialMovingAverage_4': <tf.Variable 'Variable/ExponentialMovingAverage_4:0' shape=(2, 3) dtype=float32_ref>, 'beta2_power_1/ExponentialMovingAverage_3': <tf.Variable 'beta2_power_1:0' shape=() dtype=float32_ref>, 'Variable/Adam/ExponentialMovingAverage': <tf.Variable 'Variable/Adam/ExponentialMovingAverage:0' shape=(2, 3) dtype=float32_ref>, 'v1_1/ExponentialMovingAverage': <tf.Variable 'v1_1:0' shape=(1,) dtype=float32_ref>, 'Variable_4/ExponentialMovingAverage_5': <tf.Variable 'Variable_4:0' shape=(500,) dtype=float32_ref>, 'Variable_7/ExponentialMovingAverage_3': <tf.Variable 'Variable_7/ExponentialMovingAverage_3:0' shape=(500, 10) dtype=float32_ref>, 'beta2_power/ExponentialMovingAverage_3': <tf.Variable 'beta2_power:0' shape=() dtype=float32_ref>, 'Variable_6/ExponentialMovingAverage': <tf.Variable 'Variable_6/ExponentialMovingAverage:0' shape=(500,) dtype=float32_ref>, 'Variable_3/ExponentialMovingAverage': <tf.Variable 'Variable_3/ExponentialMovingAverage:0' shape=(784, 500) dtype=float32_ref>, 'Variable_8/ExponentialMovingAverage': <tf.Variable 'Variable_8/ExponentialMovingAverage:0' shape=(10,) dtype=float32_ref>, 'Variable_2/ExponentialMovingAverage': <tf.Variable 'Variable_2/ExponentialMovingAverage:0' shape=(2, 1) dtype=float32_ref>, 'v_3/ExponentialMovingAverage': <tf.Variable 'v_3:0' shape=() dtype=float32_ref>, 'beta1_power_1/ExponentialMovingAverage_1': <tf.Variable 'beta1_power_1/ExponentialMovingAverage_1:0' shape=() dtype=float32_ref>, 'Variable/Adam/ExponentialMovingAverage_1': <tf.Variable 'Variable/Adam/ExponentialMovingAverage_1:0' shape=(2, 3) dtype=float32_ref>, 'beta2_power/ExponentialMovingAverage_2': <tf.Variable 'beta2_power/ExponentialMovingAverage_2:0' shape=() dtype=float32_ref>, 'Variable_2/Adam_1/ExponentialMovingAverage_3': <tf.Variable 'Variable_2/Adam_1:0' shape=(2, 1) dtype=float32_ref>, 'Variable_11/ExponentialMovingAverage': <tf.Variable 'Variable_11/ExponentialMovingAverage:0' shape=(500,) dtype=float32_ref>, 'Variable_6/ExponentialMovingAverage_5': <tf.Variable 'Variable_6:0' shape=(500,) dtype=float32_ref>, 'Variable_7/ExponentialMovingAverage': <tf.Variable 'Variable_7/ExponentialMovingAverage:0' shape=(500, 10) dtype=float32_ref>, 'Variable_1/ExponentialMovingAverage': <tf.Variable 'Variable_1/ExponentialMovingAverage:0' shape=(3, 1) dtype=float32_ref>, 'Variable_7/ExponentialMovingAverage_5': <tf.Variable 'Variable_7:0' shape=(500, 10) dtype=float32_ref>, 'Variable_1/Adam/ExponentialMovingAverage_3': <tf.Variable 'Variable_1/Adam:0' shape=(3, 1) dtype=float32_ref>, 'Variable_1/ExponentialMovingAverage_1': <tf.Variable 'Variable_1/ExponentialMovingAverage_1:0' shape=(3, 1) dtype=float32_ref>, 'beta2_power/ExponentialMovingAverage_1': <tf.Variable 'beta2_power/ExponentialMovingAverage_1:0' shape=() dtype=float32_ref>, 'Variable_2/Adam/ExponentialMovingAverage': <tf.Variable 'Variable_2/Adam/ExponentialMovingAverage:0' shape=(2, 1) dtype=float32_ref>, 'Variable_5/ExponentialMovingAverage_1': <tf.Variable 'Variable_5/ExponentialMovingAverage_1:0' shape=(784, 500) dtype=float32_ref>, 'Variable_2/ExponentialMovingAverage_5': <tf.Variable 'Variable_2:0' shape=(2, 1) dtype=float32_ref>, 'beta1_power/ExponentialMovingAverage_3': <tf.Variable 'beta1_power:0' shape=() dtype=float32_ref>, 'Variable_14': <tf.Variable 'Variable_14:0' shape=() dtype=int32_ref>, 'beta1_power_1/ExponentialMovingAverage_2': <tf.Variable 'beta1_power_1/ExponentialMovingAverage_2:0' shape=() dtype=float32_ref>, 'Variable/ExponentialMovingAverage_2': <tf.Variable 'Variable/ExponentialMovingAverage_2:0' shape=(2, 3) dtype=float32_ref>, 'Variable_1/ExponentialMovingAverage_4': <tf.Variable 'Variable_1/ExponentialMovingAverage_4:0' shape=(3, 1) dtype=float32_ref>, 'Variable_6/ExponentialMovingAverage_3': <tf.Variable 'Variable_6/ExponentialMovingAverage_3:0' shape=(500,) dtype=float32_ref>, 'Variable_1/Adam_1/ExponentialMovingAverage_2': <tf.Variable 'Variable_1/Adam_1/ExponentialMovingAverage_2:0' shape=(3, 1) dtype=float32_ref>, 'Variable_5/ExponentialMovingAverage_4': <tf.Variable 'Variable_5/ExponentialMovingAverage_4:0' shape=(784, 500) dtype=float32_ref>, 'Variable_1/ExponentialMovingAverage_3': <tf.Variable 'Variable_1/ExponentialMovingAverage_3:0' shape=(3, 1) dtype=float32_ref>, 'Variable_4/ExponentialMovingAverage_4': <tf.Variable 'Variable_4/ExponentialMovingAverage_4:0' shape=(500,) dtype=float32_ref>, 'Variable_1/Adam_1/ExponentialMovingAverage_1': <tf.Variable 'Variable_1/Adam_1/ExponentialMovingAverage_1:0' shape=(3, 1) dtype=float32_ref>, 'Variable_1/ExponentialMovingAverage_5': <tf.Variable 'Variable_1:0' shape=(3, 1) dtype=float32_ref>, 'Variable_2/Adam/ExponentialMovingAverage_2': <tf.Variable 'Variable_2/Adam/ExponentialMovingAverage_2:0' shape=(2, 1) dtype=float32_ref>}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from model/model_2.ckpt\n"
     ]
    },
    {
     "ename": "NotFoundError",
     "evalue": "Key v_4/ExponentialMovingAverage not found in checkpoint\n\t [[Node: save_9/RestoreV2_124 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_arg_save_9/Const_0_0, save_9/RestoreV2_124/tensor_names, save_9/RestoreV2_124/shape_and_slices)]]\n\nCaused by op 'save_9/RestoreV2_124', defined at:\n  File \"/Users/colinzuo/anaconda/envs/python35/lib/python3.5/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/Users/colinzuo/anaconda/envs/python35/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/Users/colinzuo/anaconda/envs/python35/lib/python3.5/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/Users/colinzuo/anaconda/envs/python35/lib/python3.5/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/Users/colinzuo/anaconda/envs/python35/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/Users/colinzuo/anaconda/envs/python35/lib/python3.5/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/Users/colinzuo/anaconda/envs/python35/lib/python3.5/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/Users/colinzuo/anaconda/envs/python35/lib/python3.5/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/colinzuo/anaconda/envs/python35/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/Users/colinzuo/anaconda/envs/python35/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/Users/colinzuo/anaconda/envs/python35/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/Users/colinzuo/anaconda/envs/python35/lib/python3.5/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/colinzuo/anaconda/envs/python35/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/Users/colinzuo/anaconda/envs/python35/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/Users/colinzuo/anaconda/envs/python35/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/Users/colinzuo/anaconda/envs/python35/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Users/colinzuo/anaconda/envs/python35/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/Users/colinzuo/anaconda/envs/python35/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Users/colinzuo/anaconda/envs/python35/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/Users/colinzuo/anaconda/envs/python35/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-29-3ffeaa1945b1>\", line 9, in <module>\n    saver = tf.train.Saver(ema.variables_to_restore())\n  File \"/Users/colinzuo/anaconda/envs/python35/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 1139, in __init__\n    self.build()\n  File \"/Users/colinzuo/anaconda/envs/python35/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 1170, in build\n    restore_sequentially=self._restore_sequentially)\n  File \"/Users/colinzuo/anaconda/envs/python35/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 691, in build\n    restore_sequentially, reshape)\n  File \"/Users/colinzuo/anaconda/envs/python35/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 407, in _AddRestoreOps\n    tensors = self.restore_op(filename_tensor, saveable, preferred_shard)\n  File \"/Users/colinzuo/anaconda/envs/python35/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 247, in restore_op\n    [spec.tensor.dtype])[0])\n  File \"/Users/colinzuo/anaconda/envs/python35/lib/python3.5/site-packages/tensorflow/python/ops/gen_io_ops.py\", line 640, in restore_v2\n    dtypes=dtypes, name=name)\n  File \"/Users/colinzuo/anaconda/envs/python35/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"/Users/colinzuo/anaconda/envs/python35/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2506, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/Users/colinzuo/anaconda/envs/python35/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1269, in __init__\n    self._traceback = _extract_stack()\n\nNotFoundError (see above for traceback): Key v_4/ExponentialMovingAverage not found in checkpoint\n\t [[Node: save_9/RestoreV2_124 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_arg_save_9/Const_0_0, save_9/RestoreV2_124/tensor_names, save_9/RestoreV2_124/shape_and_slices)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/Users/colinzuo/anaconda/envs/python35/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/colinzuo/anaconda/envs/python35/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1120\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1121\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/colinzuo/anaconda/envs/python35/lib/python3.5/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/colinzuo/anaconda/envs/python35/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[0;34m()\u001b[0m\n\u001b[1;32m    465\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[1;32m    467\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: Key v_4/ExponentialMovingAverage not found in checkpoint\n\t [[Node: save_9/RestoreV2_124 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_arg_save_9/Const_0_0, save_9/RestoreV2_124/tensor_names, save_9/RestoreV2_124/shape_and_slices)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-3ffeaa1945b1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/colinzuo/anaconda/envs/python35/lib/python3.5/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, sess, save_path)\u001b[0m\n\u001b[1;32m   1546\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Restoring parameters from %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1547\u001b[0m     sess.run(self.saver_def.restore_op_name,\n\u001b[0;32m-> 1548\u001b[0;31m              {self.saver_def.filename_tensor_name: save_path})\n\u001b[0m\u001b[1;32m   1549\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1550\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/colinzuo/anaconda/envs/python35/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    787\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 789\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    790\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/colinzuo/anaconda/envs/python35/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    995\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 997\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    998\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/colinzuo/anaconda/envs/python35/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1130\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1132\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1133\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/Users/colinzuo/anaconda/envs/python35/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1150\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: Key v_4/ExponentialMovingAverage not found in checkpoint\n\t [[Node: save_9/RestoreV2_124 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_arg_save_9/Const_0_0, save_9/RestoreV2_124/tensor_names, save_9/RestoreV2_124/shape_and_slices)]]\n\nCaused by op 'save_9/RestoreV2_124', defined at:\n  File \"/Users/colinzuo/anaconda/envs/python35/lib/python3.5/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/Users/colinzuo/anaconda/envs/python35/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/Users/colinzuo/anaconda/envs/python35/lib/python3.5/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/Users/colinzuo/anaconda/envs/python35/lib/python3.5/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/Users/colinzuo/anaconda/envs/python35/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/Users/colinzuo/anaconda/envs/python35/lib/python3.5/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/Users/colinzuo/anaconda/envs/python35/lib/python3.5/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/Users/colinzuo/anaconda/envs/python35/lib/python3.5/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/colinzuo/anaconda/envs/python35/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/Users/colinzuo/anaconda/envs/python35/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/Users/colinzuo/anaconda/envs/python35/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/Users/colinzuo/anaconda/envs/python35/lib/python3.5/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/colinzuo/anaconda/envs/python35/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/Users/colinzuo/anaconda/envs/python35/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/Users/colinzuo/anaconda/envs/python35/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/Users/colinzuo/anaconda/envs/python35/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Users/colinzuo/anaconda/envs/python35/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/Users/colinzuo/anaconda/envs/python35/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Users/colinzuo/anaconda/envs/python35/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/Users/colinzuo/anaconda/envs/python35/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-29-3ffeaa1945b1>\", line 9, in <module>\n    saver = tf.train.Saver(ema.variables_to_restore())\n  File \"/Users/colinzuo/anaconda/envs/python35/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 1139, in __init__\n    self.build()\n  File \"/Users/colinzuo/anaconda/envs/python35/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 1170, in build\n    restore_sequentially=self._restore_sequentially)\n  File \"/Users/colinzuo/anaconda/envs/python35/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 691, in build\n    restore_sequentially, reshape)\n  File \"/Users/colinzuo/anaconda/envs/python35/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 407, in _AddRestoreOps\n    tensors = self.restore_op(filename_tensor, saveable, preferred_shard)\n  File \"/Users/colinzuo/anaconda/envs/python35/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 247, in restore_op\n    [spec.tensor.dtype])[0])\n  File \"/Users/colinzuo/anaconda/envs/python35/lib/python3.5/site-packages/tensorflow/python/ops/gen_io_ops.py\", line 640, in restore_v2\n    dtypes=dtypes, name=name)\n  File \"/Users/colinzuo/anaconda/envs/python35/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"/Users/colinzuo/anaconda/envs/python35/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2506, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/Users/colinzuo/anaconda/envs/python35/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1269, in __init__\n    self._traceback = _extract_stack()\n\nNotFoundError (see above for traceback): Key v_4/ExponentialMovingAverage not found in checkpoint\n\t [[Node: save_9/RestoreV2_124 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_arg_save_9/Const_0_0, save_9/RestoreV2_124/tensor_names, save_9/RestoreV2_124/shape_and_slices)]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "v = tf.Variable(0, dtype=tf.float32, name=\"v\")\n",
    "ema = tf.train.ExponentialMovingAverage(0.99)\n",
    "\n",
    "print(ema.variables_to_restore())\n",
    "    \n",
    "saver = tf.train.Saver(ema.variables_to_restore())\n",
    "model_path = os.path.join(\"model\", \"model_2.ckpt\")\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, model_path)\n",
    "    print(sess.run(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import graph_util\n",
    "import os\n",
    "\n",
    "v1 = tf.Variable(tf.constant(1.0, shape=[1]), name='v1')\n",
    "v2 = tf.Variable(tf.constant(2.0, shape=[2]), name='v2')\n",
    "result = v1 + v2\n",
    "\n",
    "model_path = os.path.join(\"model\", \"combined_model.pb\")\n",
    "\n",
    "init_op = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init_op)\n",
    "    \n",
    "    graph_def = tf.get_default_graph().as_graph_def()\n",
    "    output_graph_def = graph_util.convert_variables_to_constants(sess, graph_def, ['add'])\n",
    "    \n",
    "    with tf.gfile.GFile(model_path, \"wb\") as f:\n",
    "        f.write(output_graph_def.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.platform import gfile\n",
    "import os\n",
    "\n",
    "model_path = os.path.join(\"model\", \"combined_model.pb\")\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    with gfile.FastGFile(model_path, 'rb') as f:\n",
    "        graph_def = tf.GraphDef()\n",
    "        graph_def.ParseFromString(f.read())\n",
    "        \n",
    "    result = tf.import_graph_def(graph_def, return_elements=['add:0'])\n",
    "    print(sess.run(result))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
